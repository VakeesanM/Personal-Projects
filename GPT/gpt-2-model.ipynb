{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport torch.nn as nn\nimport numpy as np \nimport pandas as pd\nimport os\nimport tiktoken\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport math\nimport time\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:50.330629Z","iopub.execute_input":"2026-02-06T04:44:50.331434Z","iopub.status.idle":"2026-02-06T04:44:50.336025Z","shell.execute_reply.started":"2026-02-06T04:44:50.331400Z","shell.execute_reply":"2026-02-06T04:44:50.335312Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Tokenizer\nimport tiktoken\ntokenizer =  tiktoken.get_encoding(\"gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:50.339590Z","iopub.execute_input":"2026-02-06T04:44:50.339808Z","iopub.status.idle":"2026-02-06T04:44:51.359593Z","shell.execute_reply.started":"2026-02-06T04:44:50.339789Z","shell.execute_reply":"2026-02-06T04:44:51.358997Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def text_to_tokens(text):\n    text = tokenizer.encode(text)\n    token = torch.tensor(text).unsqueeze(0)\n    return token\ndef tokens_to_text(tokens):\n    return tokenizer.decode(tokens.squeeze(0).tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.360893Z","iopub.execute_input":"2026-02-06T04:44:51.361138Z","iopub.status.idle":"2026-02-06T04:44:51.365128Z","shell.execute_reply.started":"2026-02-06T04:44:51.361116Z","shell.execute_reply":"2026-02-06T04:44:51.364458Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n        tokens = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n\n        for i in range(0, len(tokens) - max_length, stride):\n            input_chuck = tokens[i:i+max_length]\n            target_chuck = tokens[i+1:i+max_length+1]\n            self.input_ids.append(torch.tensor(input_chuck))\n            self.target_ids.append(torch.tensor(target_chuck)) \n\n    def __len__(self):\n        return len(self.input_ids)\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]\ndef create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.366022Z","iopub.execute_input":"2026-02-06T04:44:51.366287Z","iopub.status.idle":"2026-02-06T04:44:51.385493Z","shell.execute_reply.started":"2026-02-06T04:44:51.366255Z","shell.execute_reply":"2026-02-06T04:44:51.384921Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"LLM_Config = {\n    \"vocab_size\": 50257, #All Words in LLM\n    'context_length': 256, #Size of the each row in batch\n    'emb_dim': 768, #Dimensions of Embeddinging Vectors\n    \"n_heads\": 12, #Number of Transfoemrs\n    \"n_layers\": 12, #Number of Transformer layers\n    \"drop_rate\": 0.1, #Percentage of Tokens that are dropped\n    \"qkv_bias\": False\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.386251Z","iopub.execute_input":"2026-02-06T04:44:51.386576Z","iopub.status.idle":"2026-02-06T04:44:51.399845Z","shell.execute_reply.started":"2026-02-06T04:44:51.386554Z","shell.execute_reply":"2026-02-06T04:44:51.399290Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Causual_attentionV1(torch.nn.Module):\n    def __init__(self, d_in, d_out, context_len, dropout, bias=False):\n        super().__init__()\n        self.d_out = d_out\n        self.W_query = torch.nn.Linear(d_in, d_out, bias=bias)\n        self.W_key = torch.nn.Linear(d_in, d_out, bias=bias)\n        self.W_value = torch.nn.Linear(d_in, d_out, bias=bias)\n        self.dropout = torch.nn.Dropout(dropout)\n        self.register_buffer(\"mask\", torch.triu(torch.ones(context_len,context_len), diagonal=1))\n\n    def forward(self, x):\n        b, nums_t, d_in = x.shape\n        keys = self.W_key(x)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n        attn_score = queries @ keys.transpose(1,2)\n        causal_mask = self.mask[:nums_t, :nums_t].bool()\n        attn_score = attn_score.masked_fill(causal_mask, -torch.inf)\n        attn_weights = torch.softmax(attn_score/(keys.shape[-1]**0.5), dim=-1)\n        attn_weights = self.dropout(attn_weights)\n        context_vec = attn_weights @ values\n        return context_vec\n\nclass multiheadAttentionV1(torch.nn.Module):\n    def __init__(self, d_in, d_out, context_len, dropout, num_heads, bias=False):\n        super().__init__()\n        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads\n        self.W_query = nn.Linear(d_in, d_out, bias=bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=bias)\n        self.out_proj = nn.Linear(d_out, d_out)\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\"mask\", torch.triu(torch.ones(context_len, context_len), diagonal=1))\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape\n        keys = self.W_key(x)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n\n        keys = keys.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        attn_scores = queries @ keys.transpose(-2, -1) / math.sqrt(self.head_dim)\n        causal_mask = self.mask[:num_tokens, :num_tokens].bool()\n        attn_scores = attn_scores.masked_fill(causal_mask, float(\"-inf\"))\n\n        attn_weights = torch.softmax(attn_scores, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        context = attn_weights @ values\n        context = context.transpose(1, 2).contiguous().view(b, num_tokens, self.d_out)\n\n        return self.out_proj(context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.401500Z","iopub.execute_input":"2026-02-06T04:44:51.401756Z","iopub.status.idle":"2026-02-06T04:44:51.418076Z","shell.execute_reply.started":"2026-02-06T04:44:51.401736Z","shell.execute_reply":"2026-02-06T04:44:51.417482Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch.nn as nn\nclass GPT(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n        self.trf_blocks = nn.Sequential(*[TransformerBlock (cfg) for _ in range(cfg[\"n_layers\"])])\n        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n        self.out_head.weight = self.tok_emb.weight\n    \n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos = torch.arange(seq_len, device=in_idx.device)\n        pos_embeds = self.pos_emb(pos)[None, :, :]\n        pos_embeds = self.pos_emb(pos)\n        x = tok_embeds + pos_embeds\n        x= self.drop_emb(x)\n        x= self.trf_blocks(x)\n        x= self.final_norm(x)\n        logits = self.out_head(x)\n        return logits\n\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2/torch.pi , device=x.device))  * (x + 0.044715 * x ** 3)))\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = multiheadAttentionV1(\n            d_in=cfg['emb_dim'],\n            d_out=cfg['emb_dim'],\n            context_len=cfg['context_length'],\n            dropout=cfg['drop_rate'],\n            num_heads=cfg['n_heads'],\n            bias=cfg['qkv_bias']\n        )\n\n        self.ff = FeedForward(cfg)\n        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n    def forward(self, x):\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x)\n        x= self.drop_shortcut(x)\n        x = x + shortcut\n\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        x= self.drop_shortcut(x)\n        x = x + shortcut \n        \n\n        return x\n\nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']), GELU(), nn.Linear(4* cfg['emb_dim'],cfg['emb_dim']))\n\n    def forward(self, x):\n        return self.layers(x)\n\nclass LayerNorm(nn.Module):\n    def __init__(self, emb_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim))\n    \n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, unbiased=False, keepdim=True)\n        norm_x = (x - mean)/(torch.sqrt( var+self.eps ))\n        return self.scale * norm_x + self.shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.418906Z","iopub.execute_input":"2026-02-06T04:44:51.419171Z","iopub.status.idle":"2026-02-06T04:44:51.439620Z","shell.execute_reply.started":"2026-02-06T04:44:51.419141Z","shell.execute_reply":"2026-02-06T04:44:51.439004Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class DNN(nn.Module):\n    def __init__(self, layers, shortcut):\n        super().__init__()\n        self.shortcut =shortcut\n        self.layers = nn.ModuleList([\n            nn.Sequential(nn.Linear(layers[0],layers[1]), GELU()),\n            nn.Sequential(nn.Linear(layers[1],layers[2]), GELU()),\n            nn.Sequential(nn.Linear(layers[2],layers[3]), GELU()),\n            nn.Sequential(nn.Linear(layers[3],layers[4]), GELU()),\n            nn.Sequential(nn.Linear(layers[4],layers[5]), GELU())\n        ])\n    def forward(self, x):\n        for layer in self.layers:\n            output = layer(x)\n            if self.shortcut and x.shape == output.shape:\n                x = x+output\n            else:\n                x = output\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.440523Z","iopub.execute_input":"2026-02-06T04:44:51.440785Z","iopub.status.idle":"2026-02-06T04:44:51.459634Z","shell.execute_reply.started":"2026-02-06T04:44:51.440764Z","shell.execute_reply":"2026-02-06T04:44:51.459108Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.460402Z","iopub.execute_input":"2026-02-06T04:44:51.460656Z","iopub.status.idle":"2026-02-06T04:44:51.731033Z","shell.execute_reply.started":"2026-02-06T04:44:51.460628Z","shell.execute_reply":"2026-02-06T04:44:51.730460Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def gen_text(model, idx, max_new_tokens, context_size):\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n        logits = logits[:, -1,:]\n        probas = torch.softmax(logits, dim=-1)\n        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n        idx = torch.cat((idx, idx_next), dim=1)\n    return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.731886Z","iopub.execute_input":"2026-02-06T04:44:51.732130Z","iopub.status.idle":"2026-02-06T04:44:51.745525Z","shell.execute_reply.started":"2026-02-06T04:44:51.732106Z","shell.execute_reply":"2026-02-06T04:44:51.745017Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def batch_loss(inputs, targets, model, device):\n    inputs, targets = inputs.to(device), targets.to(device)\n\n    logits = model(inputs)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), targets.flatten())\n    return loss\n\ndef calc_loss_loader(data_loader, model, device, num=None):\n    total = 0\n    if len(data_loader) == 0:\n        return float('nan')\n    elif num is None:\n        num = len(data_loader)\n    else:\n        num = min(num, len(data_loader))\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num:\n            loss = batch_loss(input_batch, target_batch, model, device)\n            total += loss.item()\n        else:\n            break\n    return total/num","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.746408Z","iopub.execute_input":"2026-02-06T04:44:51.746701Z","iopub.status.idle":"2026-02-06T04:44:51.759215Z","shell.execute_reply.started":"2026-02-06T04:44:51.746679Z","shell.execute_reply":"2026-02-06T04:44:51.758769Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def gen_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    cs = model.pos_emb.weight.shape[0]\n    encoded = text_to_tokens(start_context).to(device)\n    with torch.no_grad():\n        token_ids = gen_text(model, encoded, 50, cs)\n    text = tokens_to_text(token_ids)\n    print(text.replace('\\n', ' '))\n    model.train()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.760198Z","iopub.execute_input":"2026-02-06T04:44:51.760450Z","iopub.status.idle":"2026-02-06T04:44:51.773301Z","shell.execute_reply.started":"2026-02-06T04:44:51.760430Z","shell.execute_reply":"2026-02-06T04:44:51.772696Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#torch.manual_seed(123)\n#train_ratio = int(0.90 * len(verdict_story))\n#train = verdict_story[:train_ratio]\n#test = verdict_story[train_ratio:]\n\n#train_loader = create_dataloader_v1(train, 2, LLM_Config['context_length'],LLM_Config['context_length'], True, True, 0 )\n#test_loader = create_dataloader_v1(test, 2, LLM_Config['context_length'],LLM_Config['context_length'], False, False, 0 )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.774067Z","iopub.execute_input":"2026-02-06T04:44:51.774357Z","iopub.status.idle":"2026-02-06T04:44:51.791710Z","shell.execute_reply.started":"2026-02-06T04:44:51.774327Z","shell.execute_reply":"2026-02-06T04:44:51.791221Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def training_cycle(model, train_loader, test_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n    train_lossess, test_losses, track_tokens = [],[],[]\n    tokens_seen, gloabal_step = 0, -1\n\n    for epoch in range(num_epochs):\n        model.train()\n\n        for inputs, targets in train_loader:\n            optimizer.zero_grad()\n            loss = batch_loss(inputs, targets, model, device)\n            loss.backward()\n            optimizer.step()\n            tokens_seen += inputs.numel()\n            gloabal_step += 1\n\n            if gloabal_step % eval_freq == 0:\n                training_loss, test_loss = evalm(model, train_loader, test_loader, device, eval_iter)\n                train_lossess.append(training_loss)\n                test_losses.append(test_loss)\n                track_tokens.append(tokens_seen)\n                print(f\"Epoch: {epoch+1}, Step {gloabal_step}:\\n Train_loss:{training_loss}, Test_loss: {test_loss}\")\n\n        gen_print_sample(model, tokenizer, device, start_context)\n\n    return train_lossess, test_losses, tokens_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.792424Z","iopub.execute_input":"2026-02-06T04:44:51.792680Z","iopub.status.idle":"2026-02-06T04:44:51.807785Z","shell.execute_reply.started":"2026-02-06T04:44:51.792648Z","shell.execute_reply":"2026-02-06T04:44:51.807066Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def evalm(model, train_loader, test_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(train_loader, model, device)\n        test_loss = calc_loss_loader(test_loader, model, device)\n    model.train()\n    return train_loss, test_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.810526Z","iopub.execute_input":"2026-02-06T04:44:51.810822Z","iopub.status.idle":"2026-02-06T04:44:51.821087Z","shell.execute_reply.started":"2026-02-06T04:44:51.810802Z","shell.execute_reply":"2026-02-06T04:44:51.820392Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.822057Z","iopub.execute_input":"2026-02-06T04:44:51.822297Z","iopub.status.idle":"2026-02-06T04:44:51.838726Z","shell.execute_reply.started":"2026-02-06T04:44:51.822276Z","shell.execute_reply":"2026-02-06T04:44:51.838043Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#model.to(device)\n#optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n\n#num_epochs = 10\n#train_losses, val_lossess, tokens_seen = training_cycle(model, train_loader, test_loader, optimizer, device, num_epochs=num_epochs, eval_freq=5,eval_iter=5, \n                                                       # start_context=\"Every effort moves you\", tokenizer =tokenizer)\n#end_time = time.time()\n#print(f\"Run Time: {end_time - start_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.839640Z","iopub.execute_input":"2026-02-06T04:44:51.839969Z","iopub.status.idle":"2026-02-06T04:44:51.852154Z","shell.execute_reply.started":"2026-02-06T04:44:51.839948Z","shell.execute_reply":"2026-02-06T04:44:51.851615Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def generate(model, idx, max_new_tokens, context_size, temp=0.0, top_k=None, eos_id=0):\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n        logits = logits[:, -1, :]\n\n        if top_k is not None:\n            top_logits, _ = torch.topk(logits, top_k)\n            min_val = top_logits[:, -1].unsqueeze(-1)\n            logits = torch.where(logits < min_val, torch.full_like(logits, float(\"-inf\")), logits)\n\n        if temp > 0:\n            logits = logits / temp\n            probs = torch.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n        else:\n            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n\n        if idx_next.item() == eos_id:\n            break\n\n        idx = torch.cat((idx, idx_next), dim=1)\n\n    return idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.852813Z","iopub.execute_input":"2026-02-06T04:44:51.853076Z","iopub.status.idle":"2026-02-06T04:44:51.865760Z","shell.execute_reply.started":"2026-02-06T04:44:51.853054Z","shell.execute_reply":"2026-02-06T04:44:51.865090Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#token_ids = generate(model, text_to_tokens(\"Every effor moves you\"), 15, 256, top_k=25, temp=1.4 )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.866665Z","iopub.execute_input":"2026-02-06T04:44:51.866925Z","iopub.status.idle":"2026-02-06T04:44:51.877882Z","shell.execute_reply.started":"2026-02-06T04:44:51.866898Z","shell.execute_reply":"2026-02-06T04:44:51.877391Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import tensorflow as tf\nimport tqdm\n\nprint(tf.__version__)\nprint(tqdm.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:44:51.878625Z","iopub.execute_input":"2026-02-06T04:44:51.878887Z","iopub.status.idle":"2026-02-06T04:45:13.298500Z","shell.execute_reply.started":"2026-02-06T04:44:51.878855Z","shell.execute_reply":"2026-02-06T04:45:13.297843Z"}},"outputs":[{"name":"stderr","text":"2026-02-06 04:44:55.283055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770353095.695090      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770353095.849579      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770353096.810836      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770353096.810877      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770353096.810880      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770353096.810882      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"2.19.0\n4.67.1\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"pip install llms-from-scratch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:45:13.299322Z","iopub.execute_input":"2026-02-06T04:45:13.299760Z","iopub.status.idle":"2026-02-06T04:45:24.086941Z","shell.execute_reply.started":"2026-02-06T04:45:13.299736Z","shell.execute_reply":"2026-02-06T04:45:24.086196Z"}},"outputs":[{"name":"stdout","text":"Collecting llms-from-scratch\n  Downloading llms_from_scratch-1.0.19-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: torch>=2.2.2 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.8.0+cu126)\nRequirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.19.0)\nCollecting jupyterlab>=4.0 (from llms-from-scratch)\n  Downloading jupyterlab-4.5.3-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (0.12.0)\nRequirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (3.10.0)\nRequirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (4.67.1)\nRequirement already satisfied: numpy<2.1,>=1.26 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.0.2)\nRequirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (2.2.2)\nCollecting pip>=25.0.1 (from llms-from-scratch)\n  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch) (8.4.2)\nCollecting async-lru>=1.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n  Downloading async_lru-2.1.0-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.28.1)\nRequirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.17.1)\nRequirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (3.1.6)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.9.1)\nCollecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (2.12.5)\nRequirement already satisfied: jupyterlab-server<3,>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (2.28.0)\nRequirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.2.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (25.0)\nRequirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (75.2.0)\nRequirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.5.1)\nRequirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.4.9)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.3)\nRequirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.3.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (1.6.0)\nRequirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.19.2)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (25.9.23)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (5.29.5)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.32.5)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.0.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.75.1)\nRequirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.19.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.10.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.15.1)\nRequirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.5.3)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->llms-from-scratch) (2025.11.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (3.20.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (3.5)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2.2->llms-from-scratch) (3.4.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch) (0.45.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (0.16.0)\nRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.8.15)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.4.9)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.6.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (5.9.5)\nRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (26.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.0->llms-from-scratch) (3.0.3)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (25.1.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.3)\nRequirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.4.5)\nRequirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (5.10.4)\nRequirement already satisfied: overrides in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.7.0)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.23.1)\nRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.18.1)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.9.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch) (4.5.1)\nRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (2.17.0)\nRequirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (0.12.1)\nRequirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (4.25.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (2.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2.2->llms-from-scratch) (1.3.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (3.9)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch) (3.1.3)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (3.0.52)\nRequirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch) (0.27.1)\nRequirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.4)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.0.0)\nRequirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.0.3)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.1.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.13.5)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.21.2)\nRequirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (25.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (4.0.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.8.5)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.0.0)\nRequirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.1.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (24.11.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.2)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.14)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.0.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.8)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.23)\nRequirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.3.0)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.4.0)\nDownloading llms_from_scratch-1.0.19-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jupyterlab-4.5.3-py3-none-any.whl (12.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_lru-2.1.0-py3-none-any.whl (6.9 kB)\nDownloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pip, async-lru, jupyter-lsp, jupyterlab, llms-from-scratch\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n  Attempting uninstall: jupyter-lsp\n    Found existing installation: jupyter-lsp 1.5.1\n    Uninstalling jupyter-lsp-1.5.1:\n      Successfully uninstalled jupyter-lsp-1.5.1\n  Attempting uninstall: jupyterlab\n    Found existing installation: jupyterlab 3.6.8\n    Uninstalling jupyterlab-3.6.8:\n      Successfully uninstalled jupyterlab-3.6.8\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, but you have jupyterlab 4.5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-lru-2.1.0 jupyter-lsp-2.3.0 jupyterlab-4.5.3 llms-from-scratch-1.0.19 pip-26.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from llms_from_scratch.ch05 import download_and_load_gpt2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:45:24.088164Z","iopub.execute_input":"2026-02-06T04:45:24.088443Z","iopub.status.idle":"2026-02-06T04:45:24.096986Z","shell.execute_reply.started":"2026-02-06T04:45:24.088415Z","shell.execute_reply":"2026-02-06T04:45:24.096310Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:45:24.097980Z","iopub.execute_input":"2026-02-06T04:45:24.098254Z","iopub.status.idle":"2026-02-06T04:46:20.789323Z","shell.execute_reply.started":"2026-02-06T04:45:24.098225Z","shell.execute_reply":"2026-02-06T04:46:20.788736Z"}},"outputs":[{"name":"stderr","text":"checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 150kiB/s]\nencoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 6.03MiB/s]\nhparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 194kiB/s]\nmodel.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:54<00:00, 9.10MiB/s] \nmodel.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 12.7MiB/s]\nmodel.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 4.23MiB/s]\nvocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.38MiB/s]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"settings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:20.790267Z","iopub.execute_input":"2026-02-06T04:46:20.790564Z","iopub.status.idle":"2026-02-06T04:46:20.796204Z","shell.execute_reply.started":"2026-02-06T04:46:20.790534Z","shell.execute_reply":"2026-02-06T04:46:20.795659Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"params.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:20.797013Z","iopub.execute_input":"2026-02-06T04:46:20.797225Z","iopub.status.idle":"2026-02-06T04:46:20.812235Z","shell.execute_reply.started":"2026-02-06T04:46:20.797204Z","shell.execute_reply":"2026-02-06T04:46:20.811619Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"params['wte'].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:20.813116Z","iopub.execute_input":"2026-02-06T04:46:20.813709Z","iopub.status.idle":"2026-02-06T04:46:20.826804Z","shell.execute_reply.started":"2026-02-06T04:46:20.813684Z","shell.execute_reply":"2026-02-06T04:46:20.826239Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(50257, 768)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"GPT2_Config = LLM_Config.copy()\nGPT2_Config.update({\"context_length\": 1024, \"qkv_bias\": True})\nGPT2_Config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:20.827886Z","iopub.execute_input":"2026-02-06T04:46:20.828422Z","iopub.status.idle":"2026-02-06T04:46:20.841869Z","shell.execute_reply.started":"2026-02-06T04:46:20.828392Z","shell.execute_reply":"2026-02-06T04:46:20.841212Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'vocab_size': 50257,\n 'context_length': 1024,\n 'emb_dim': 768,\n 'n_heads': 12,\n 'n_layers': 12,\n 'drop_rate': 0.1,\n 'qkv_bias': True}"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"def assign(left, right):\n    if left.shape != right.shape:\n        raise ValueError()\n    return torch.nn.Parameter(torch.tensor(right))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:20.842728Z","iopub.execute_input":"2026-02-06T04:46:20.843254Z","iopub.status.idle":"2026-02-06T04:46:20.855516Z","shell.execute_reply.started":"2026-02-06T04:46:20.843231Z","shell.execute_reply":"2026-02-06T04:46:20.854788Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# I can't possibly train a LLM using my barely working PC\n# So I will be using the GPT2 publiccally avalible weights and load them into my model\n\ndef load_weights(gpt, params):\n    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n\n    for b in range(len(params[\"blocks\"])):\n        #This is loading the weights of the Multihead Attention \n        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"]['c_attn'])['w'], 3, axis =-1)\n        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n        #This is loading the bais\n        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"]['c_attn'])['b'], 3, axis =-1)\n        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n        #This is loading the out_projection weights and baises\n        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight,params[\"blocks\"][b][\"attn\"]['c_proj']['w'].T)\n        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias,params[\"blocks\"][b][\"attn\"]['c_proj']['b'])\n        #Loading The Feed Forward Layers\n        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"]['c_fc']['w'].T)\n        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"]['c_fc']['b'])\n        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"]['c_proj']['w'].T)\n        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"]['c_proj']['b'])\n        #loading the Normiliaztion Layers 1 and 2\n        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"]['g'])\n        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"]['b'])\n        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"]['g'])\n        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"]['b'])\n        #loads the last layer\n    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n    gpt.out_head.weight = gpt.tok_emb.weight\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:20.856521Z","iopub.execute_input":"2026-02-06T04:46:20.856784Z","iopub.status.idle":"2026-02-06T04:46:20.870730Z","shell.execute_reply.started":"2026-02-06T04:46:20.856763Z","shell.execute_reply":"2026-02-06T04:46:20.870180Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"model = GPT(GPT2_Config)\n\nload_weights(model, params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:20.871687Z","iopub.execute_input":"2026-02-06T04:46:20.872060Z","iopub.status.idle":"2026-02-06T04:46:22.409811Z","shell.execute_reply.started":"2026-02-06T04:46:20.872031Z","shell.execute_reply":"2026-02-06T04:46:22.409013Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def talk(talk):\n    token_ids = generate(model, text_to_tokens(talk), 30, 1024, top_k=25, temp=1.4 )\n    return tokens_to_text(token_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:22.439516Z","iopub.execute_input":"2026-02-06T04:46:22.439759Z","iopub.status.idle":"2026-02-06T04:46:22.450895Z","shell.execute_reply.started":"2026-02-06T04:46:22.439739Z","shell.execute_reply":"2026-02-06T04:46:22.450229Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"print(talk(\"3rd World Countries have high cases of poverty and diseases, with the most common disease being\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:22.451799Z","iopub.execute_input":"2026-02-06T04:46:22.452150Z","iopub.status.idle":"2026-02-06T04:46:26.142635Z","shell.execute_reply.started":"2026-02-06T04:46:22.452121Z","shell.execute_reply":"2026-02-06T04:46:26.141875Z"}},"outputs":[{"name":"stdout","text":"3rd World Countries have high cases of poverty and diseases, with the most common disease being hepatitis B [1], chronic liver disease [2] and kidney disease.\n\nThe World Bank reported in 2014 it has the highest mortality rates per\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/gpt_state_dict.pt\")\n# This line exports the weights, so that can load in it in main.py.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T04:46:54.159139Z","iopub.execute_input":"2026-02-06T04:46:54.159450Z","iopub.status.idle":"2026-02-06T04:46:54.639013Z","shell.execute_reply.started":"2026-02-06T04:46:54.159418Z","shell.execute_reply":"2026-02-06T04:46:54.638392Z"}},"outputs":[],"execution_count":40}]}